There's not too much to this challenge. We add another opcode:

```c
// chunk.h
typedef enum {
  OP_CONSTANT,
  OP_CONSTANT_LONG, // <--
  OP_RETURN,
} OpCode;
```

Declare the new function:

```c
// chunk.h
void writeConstant(Chunk* chunk, Value value, int line);
```

And implement it:

```c
// chunk.c
void writeConstant(Chunk* chunk, Value value, int line) {
  int index = addConstant(chunk, value);
  if (index < 256) {
    writeChunk(chunk, OP_CONSTANT, line);
    writeChunk(chunk, (uint8_t)index, line);
  } else {
    writeChunk(chunk, OP_CONSTANT_LONG, line);
    writeChunk(chunk, (uint8_t)(index & 0xff), line);
    writeChunk(chunk, (uint8_t)((index >> 8) & 0xff), line);
    writeChunk(chunk, (uint8_t)((index >> 16) & 0xff), line);
  }
}
```

This is pretty straightforward. We add the constant to the array and get the
index back. If the index fits in one byte, we use the short opcode and just
write the single byte.

Otherwise, we write the long opcode. Then we need to split the value into
multiple bytes. It's up to us to pick an endianness -- do we put the most
significant byte first or last? For no particular reason, I went with
little-endian, the same order x86 uses.

We want to be able to disassemble it too, so we add another case:

```c
// debug.c
    case OP_CONSTANT_LONG:
      return longConstantInstruction("OP_CONSTANT_LONG", chunk, offset);
```

And that calls:

```c
// debug.c
static int longConstantInstruction(const char* name, Chunk* chunk,
                                   int offset) {
  uint32_t constant = chunk->code[offset + 1] |
                     (chunk->code[offset + 2] << 8) |
                     (chunk->code[offset + 3] << 16);
  printf("%-16s %4d '", name, constant);
  printValue(chunk->constants.values[constant]);
  printf("'\n");
  return offset + 4;
}
```

Again, we need to worry about endianness and we need to make sure we decode
the bytes the same way we encoded them. (If we were interpreting these, we'd
need to do it right there too.)

This isn't a bad approach. The main trade-off is that it adds to the number of
instructions we have. That has a couple of downsides:

- It makes our interpreter more complex. This is pretty minor, though.

- It uses up an opcode. If we want all opcodes to fit in a single byte, we can
  only have 256 different ones. Our toy interpreter won't need anywhere near
  that many, but a full-featured bytecode VM like the JVM or CPython can end up
  using lots of them and we may not want to sacrifice another opcode for this.

- It *might* slightly slow down the interpreter. Machine code has to be loaded
  onto the CPU before it can be executed, so locality affects it too. The less
  code you have in your code interpreter bytecode execution loop, the fewer
  cache misses you'll have as it dispatches to different instructions.

  Having multiple instructions, each with their own code, for handing constants
  of different sizes increases the code size of the core interpreter loop and
  might cause a few more caches misses.

In practice, though, none of these is fatal and having multiple instructions
of different sizes isn't a terrible idea.
