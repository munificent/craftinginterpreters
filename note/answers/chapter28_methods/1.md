An easy optimization is to cache the initializer directly in the ObjClass to
avoid the hash table lookup:

```c
typedef struct sObjClass {
  Obj obj;
  ObjString* name;
  Value initializer; // <--
  Table methods;
} ObjClass;
```

It starts out nil:

```c
ObjClass* newClass(ObjString* name) {
  ObjClass* klass = ALLOCATE_OBJ(ObjClass, OBJ_CLASS);
  klass->name = name;
  klass->initializer = NIL_VAL; // <--
  initTable(&klass->methods);
  return klass;
}
```

When a method is defined, if it's the initializer, then we also store it in
that field:

```c
static void defineMethod(ObjString* name) {
  Value method = peek(0);
  ObjClass* klass = AS_CLASS(peek(1));
  tableSet(&klass->methods, name, method);
  if (name == vm.initString) klass->initializer = method; // <--
  pop();
}
```

Then in `callValue()` we use that instead of looking for the initializer in the
method table:

```c
      case OBJ_CLASS: {
        ObjClass* klass = AS_CLASS(callee);
        vm.stackTop[-argCount - 1] = OBJ_VAL(newInstance(klass));
        if (!IS_NIL(klass->initializer)) {                       // <--
          return call(AS_CLOSURE(klass->initializer), argCount); // <--
        } else if (argCount != 0) {
          runtimeError("Expected 0 arguments but got %d.", argCount);
          return false;
        }
```

It's a reasonable little optimization. On my machine, it doesn't really affect
perf in a noticeable way. Even in a benchmark that stresses creating instances,
it's only a marginal improvement. That's because the heap allocation and GC of
the instances dominates the runtime.

However if we had a more sophisticated implementation with its own faster
memory allocator, then that might go down. At that point, looking up the
initializer could be a larger piece of the time to instantiate and object and
might be more important to speed up.
