One could spend a lot of time tweaking this and optimizing. Here's a simple
implementation. First, in the compiler we need to not emit `OP_CLOSURE` and the
subsequent operands if there are no upvalues. Instead, we just emit an
`OP_CONSTANT` to load the function like we did before we had closures.

```c
  // Create the function object.
  ObjFunction* function = endCompiler();
  // Remove 7 lines and add:
  uint8_t functionConstant = makeConstant(OBJ_VAL(function));
  if (function->upvalueCount > 0) {
    emitBytes(OP_CLOSURE, functionConstant);

    // Emit arguments for each upvalue to know whether to capture a local
    // or an upvalue.
    for (int i = 0; i < function->upvalueCount; i++) {
      emitByte(compiler.upvalues[i].isLocal ? 1 : 0);
      emitByte(compiler.upvalues[i].index);
    }
  } else {
    // No need to create a closure.
    emitBytes(OP_CONSTANT, functionConstant);
  }
  // End.
}
```

In the VM, we first need to change CallFrame. We can't rely on the current
function always being an ObjClosure:

```c
typedef struct {
  // Remove 1 line and add:
  Obj* function;
  // End.
  uint8_t* ip;
  Value* slots;
} CallFrame;
```

We store it as an `Obj*` since it may be either an ObjClosure or ObjFunction.
Since Obj contains the type type, we can use that at runtime to see which kind
of function we have.

Over in the implementation, add:

```c
static inline ObjFunction* getFrameFunction(CallFrame* frame) {
  if (frame->function->type == OBJ_FUNCTION) {
    return (ObjFunction*)frame->function;
  } else {
    return ((ObjClosure*)frame->function)->function;
  }
}
```

Accessing the underlying ObjFunction for a given CallFrame requires some
conditional logic. We need to do this in a couple of places, including macros,
so I wrapped it in a function that the compiler will hopefully inline for us.

In `runtimeError()`, replace:

```c
    ObjFunction* function = frame->closure->function;
```

With:

```c
    ObjFunction* function = getFrameFunction(frame);
```

In `callValue()`, we need to handle both kinds of callable objects. There are
a few ways to do this, but I split `call()` into two functions:

```c
      case OBJ_CLOSURE:
        return callClosure(AS_CLOSURE(callee), argCount);
      case OBJ_FUNCTION:
        return callFunction(AS_FUNCTION(callee), argCount);
```

Delete the old `call()` and replace it with:

```c
static bool call(Obj* callee, ObjFunction* function, int argCount) {
  if (argCount != function->arity) {
    runtimeError("Expected %d arguments but got %d.",
        function->arity, argCount);
    return false;
  }

  if (vm.frameCount == FRAMES_MAX) {
    runtimeError("Stack overflow.");
    return false;
  }

  CallFrame* frame = &vm.frames[vm.frameCount++];
  frame->function = (Obj*)callee;
  frame->ip = function->chunk.code;

  frame->slots = vm.stackTop - argCount - 1;
  return true;
}

static bool callClosure(ObjClosure* closure, int argCount) {
  return call((Obj*)closure, closure->function, argCount);
}

static bool callFunction(ObjFunction* function, int argCount) {
  return call((Obj*)function, function, argCount);
}
```

Most of the code is the same, but we have to jump through a few hoops to handle
the level of indirection in ObjClosure.

I did a little benchmarking. On our old fib program that doesn't use any
closures, this change makes it a few percent slower. Unsurprising because
there's a little more conditional logic when accessing the function from a
CallFrame. I was actually surprised there wasn't a bigger performance cost.

Then I made a little synthetic benchmark to stress closure creation:

```
for (var i = 0; i < 10; i = i + 1) {
  var start = clock();
  var sum = 0;
  for (var j = 0; j < 1000000; j = j + 1) {
    fun outer(a, b, c) {
      fun inner() {
        return a + b + c;
      }
      return inner;
    }

    var closure = outer(j, j, j);
    sum = sum + closure();
  }

  print sum;
  print clock() - start;
}
```

This program is obviously pathological. Real code rarely creates so many
functions and closures. But on this program, there was a significant improvement
with the new code. About 24% faster. I think most of this is because we don't
have to create a closure for each declaration of `outer()`.

Overall, I'm not sure if this optimization is worth it. I'd want to try it on
real-world code that uses closures in an idiomatic way.
